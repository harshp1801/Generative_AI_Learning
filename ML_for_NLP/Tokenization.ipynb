{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a21253-ffbd-4960-8f00-fbee56dda9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question find the differences between nltk and spacy__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444af8b9-d2ad-4d05-a77e-7ce130559d71",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f6f985-4e31-49ae-b51f-39b4f100960f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/harsh-ideapad/anaconda3/lib/python3.12/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/harsh-ideapad/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/harsh-ideapad/anaconda3/lib/python3.12/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/harsh-ideapad/anaconda3/lib/python3.12/site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in /home/harsh-ideapad/anaconda3/lib/python3.12/site-packages (from nltk) (4.67.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/harsh-\n",
      "[nltk_data]     ideapad/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19cc013f-4d3e-4fb9-81fd-b384569e76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\" Data science is an interdisciplinary academic field[1] that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge from potentially noisy, structured, or unstructured data.[2]\n",
    "Data science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.[4]\n",
    "They often don’t carry consistent signal across users. For example\n",
    "Data science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data.[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.[6] However, data science is different from computer science and information science.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7604e593-e013-4729-a50a-f29fb8c98445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data science is an interdisciplinary academic field[1] that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge from potentially noisy, structured, or unstructured data.[2]\n",
      "Data science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.[4]\n",
      "They often don’t carry consistent signal across users. For example\n",
      "Data science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data.[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.[6] However, data science is different from computer science and information science.\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae9ee32-6b39-40dc-b2a6-bc2cdae90a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419f42f9-e391-48a4-a6e3-806548923d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557de92e-3c27-4b81-af17-7e02cc04e41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Data science is an interdisciplinary academic field[1] that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge from potentially noisy, structured, or unstructured data.',\n",
       " '[2]\\nData science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).',\n",
       " '[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.',\n",
       " '[4]\\nThey often don’t carry consistent signal across users.',\n",
       " 'For example\\nData science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data.',\n",
       " '[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.',\n",
       " '[6] However, data science is different from computer science and information science.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(sentences))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7a5881-ff54-4d5d-9b28-bef8e2725595",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sentence-->words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6b8d8c-22ef-414e-95f7-9f7f766029ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17ca0bc7-b90d-49a9-be1c-07168747825c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'an',\n",
       " 'interdisciplinary',\n",
       " 'academic',\n",
       " 'field',\n",
       " '[',\n",
       " '1',\n",
       " ']',\n",
       " 'that',\n",
       " 'uses',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'scientific',\n",
       " 'computing',\n",
       " ',',\n",
       " 'scientific',\n",
       " 'methods',\n",
       " ',',\n",
       " 'processing',\n",
       " ',',\n",
       " 'scientific',\n",
       " 'visualization',\n",
       " ',',\n",
       " 'algorithms',\n",
       " 'and',\n",
       " 'systems',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'or',\n",
       " 'extrapolate',\n",
       " 'knowledge',\n",
       " 'from',\n",
       " 'potentially',\n",
       " 'noisy',\n",
       " ',',\n",
       " 'structured',\n",
       " ',',\n",
       " 'or',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " '.',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'also',\n",
       " 'integrates',\n",
       " 'domain',\n",
       " 'knowledge',\n",
       " 'from',\n",
       " 'the',\n",
       " 'underlying',\n",
       " 'application',\n",
       " 'domain',\n",
       " '(',\n",
       " 'e.g.',\n",
       " ',',\n",
       " 'natural',\n",
       " 'sciences',\n",
       " ',',\n",
       " 'information',\n",
       " 'technology',\n",
       " ',',\n",
       " 'and',\n",
       " 'medicine',\n",
       " ')',\n",
       " '.',\n",
       " '[',\n",
       " '3',\n",
       " ']',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'multifaceted',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'described',\n",
       " 'as',\n",
       " 'a',\n",
       " 'science',\n",
       " ',',\n",
       " 'a',\n",
       " 'research',\n",
       " 'paradigm',\n",
       " ',',\n",
       " 'a',\n",
       " 'research',\n",
       " 'method',\n",
       " ',',\n",
       " 'a',\n",
       " 'discipline',\n",
       " ',',\n",
       " 'a',\n",
       " 'workflow',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'profession',\n",
       " '.',\n",
       " '[',\n",
       " '4',\n",
       " ']',\n",
       " 'They',\n",
       " 'often',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'carry',\n",
       " 'consistent',\n",
       " 'signal',\n",
       " 'across',\n",
       " 'users',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'is',\n",
       " '``',\n",
       " 'a',\n",
       " 'concept',\n",
       " 'to',\n",
       " 'unify',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'data',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'informatics',\n",
       " ',',\n",
       " 'and',\n",
       " 'their',\n",
       " 'related',\n",
       " 'methods',\n",
       " \"''\",\n",
       " 'to',\n",
       " '``',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'actual',\n",
       " 'phenomena',\n",
       " \"''\",\n",
       " 'with',\n",
       " 'data',\n",
       " '.',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " 'It',\n",
       " 'uses',\n",
       " 'techniques',\n",
       " 'and',\n",
       " 'theories',\n",
       " 'drawn',\n",
       " 'from',\n",
       " 'many',\n",
       " 'fields',\n",
       " 'within',\n",
       " 'the',\n",
       " 'context',\n",
       " 'of',\n",
       " 'mathematics',\n",
       " ',',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'information',\n",
       " 'science',\n",
       " ',',\n",
       " 'and',\n",
       " 'domain',\n",
       " 'knowledge',\n",
       " '.',\n",
       " '[',\n",
       " '6',\n",
       " ']',\n",
       " 'However',\n",
       " ',',\n",
       " 'data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'different',\n",
       " 'from',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'and',\n",
       " 'information',\n",
       " 'science',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d498419-3bbe-4f75-9720-a16e60f7b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data', 'science', 'is', 'an', 'interdisciplinary', 'academic', 'field', '[', '1', ']', 'that', 'uses', 'statistics', ',', 'scientific', 'computing', ',', 'scientific', 'methods', ',', 'processing', ',', 'scientific', 'visualization', ',', 'algorithms', 'and', 'systems', 'to', 'extract', 'or', 'extrapolate', 'knowledge', 'from', 'potentially', 'noisy', ',', 'structured', ',', 'or', 'unstructured', 'data', '.']\n",
      "['[', '2', ']', 'Data', 'science', 'also', 'integrates', 'domain', 'knowledge', 'from', 'the', 'underlying', 'application', 'domain', '(', 'e.g.', ',', 'natural', 'sciences', ',', 'information', 'technology', ',', 'and', 'medicine', ')', '.']\n",
      "['[', '3', ']', 'Data', 'science', 'is', 'multifaceted', 'and', 'can', 'be', 'described', 'as', 'a', 'science', ',', 'a', 'research', 'paradigm', ',', 'a', 'research', 'method', ',', 'a', 'discipline', ',', 'a', 'workflow', ',', 'and', 'a', 'profession', '.']\n",
      "['[', '4', ']', 'They', 'often', 'don', '’', 't', 'carry', 'consistent', 'signal', 'across', 'users', '.']\n",
      "['For', 'example', 'Data', 'science', 'is', '``', 'a', 'concept', 'to', 'unify', 'statistics', ',', 'data', 'analysis', ',', 'informatics', ',', 'and', 'their', 'related', 'methods', \"''\", 'to', '``', 'understand', 'and', 'analyze', 'actual', 'phenomena', \"''\", 'with', 'data', '.']\n",
      "['[', '5', ']', 'It', 'uses', 'techniques', 'and', 'theories', 'drawn', 'from', 'many', 'fields', 'within', 'the', 'context', 'of', 'mathematics', ',', 'statistics', ',', 'computer', 'science', ',', 'information', 'science', ',', 'and', 'domain', 'knowledge', '.']\n",
      "['[', '6', ']', 'However', ',', 'data', 'science', 'is', 'different', 'from', 'computer', 'science', 'and', 'information', 'science', '.']\n"
     ]
    }
   ],
   "source": [
    "for line in sentences:\n",
    "    print(word_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1274b4d-e995-4187-bce0-5bab285a86eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2ed8ea-154f-4137-a2f7-38cbb44f0bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data', 'science', 'is', 'an', 'interdisciplinary', 'academic', 'field', '[', '1', ']', 'that', 'uses', 'statistics', ',', 'scientific', 'computing', ',', 'scientific', 'methods', ',', 'processing', ',', 'scientific', 'visualization', ',', 'algorithms', 'and', 'systems', 'to', 'extract', 'or', 'extrapolate', 'knowledge', 'from', 'potentially', 'noisy', ',', 'structured', ',', 'or', 'unstructured', 'data', '.']\n",
      "['[', '2', ']', 'Data', 'science', 'also', 'integrates', 'domain', 'knowledge', 'from', 'the', 'underlying', 'application', 'domain', '(', 'e', '.', 'g', '.,', 'natural', 'sciences', ',', 'information', 'technology', ',', 'and', 'medicine', ').']\n",
      "['[', '3', ']', 'Data', 'science', 'is', 'multifaceted', 'and', 'can', 'be', 'described', 'as', 'a', 'science', ',', 'a', 'research', 'paradigm', ',', 'a', 'research', 'method', ',', 'a', 'discipline', ',', 'a', 'workflow', ',', 'and', 'a', 'profession', '.']\n",
      "['[', '4', ']', 'They', 'often', 'don', '’', 't', 'carry', 'consistent', 'signal', 'across', 'users', '.']\n",
      "['For', 'example', 'Data', 'science', 'is', '\"', 'a', 'concept', 'to', 'unify', 'statistics', ',', 'data', 'analysis', ',', 'informatics', ',', 'and', 'their', 'related', 'methods', '\"', 'to', '\"', 'understand', 'and', 'analyze', 'actual', 'phenomena', '\"', 'with', 'data', '.']\n",
      "['[', '5', ']', 'It', 'uses', 'techniques', 'and', 'theories', 'drawn', 'from', 'many', 'fields', 'within', 'the', 'context', 'of', 'mathematics', ',', 'statistics', ',', 'computer', 'science', ',', 'information', 'science', ',', 'and', 'domain', 'knowledge', '.']\n",
      "['[', '6', ']', 'However', ',', 'data', 'science', 'is', 'different', 'from', 'computer', 'science', 'and', 'information', 'science', '.']\n"
     ]
    }
   ],
   "source": [
    "for line in sentences:\n",
    "    print(wordpunct_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a43c99cf-bf09-4b3e-9be3-25d71eaf2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tbwt = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "393d923c-d662-49ac-a7c7-621e95d90294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data', 'science', 'is', 'an', 'interdisciplinary', 'academic', 'field', '[', '1', ']', 'that', 'uses', 'statistics', ',', 'scientific', 'computing', ',', 'scientific', 'methods', ',', 'processing', ',', 'scientific', 'visualization', ',', 'algorithms', 'and', 'systems', 'to', 'extract', 'or', 'extrapolate', 'knowledge', 'from', 'potentially', 'noisy', ',', 'structured', ',', 'or', 'unstructured', 'data', '.']\n",
      "['[', '2', ']', 'Data', 'science', 'also', 'integrates', 'domain', 'knowledge', 'from', 'the', 'underlying', 'application', 'domain', '(', 'e.g.', ',', 'natural', 'sciences', ',', 'information', 'technology', ',', 'and', 'medicine', ')', '.']\n",
      "['[', '3', ']', 'Data', 'science', 'is', 'multifaceted', 'and', 'can', 'be', 'described', 'as', 'a', 'science', ',', 'a', 'research', 'paradigm', ',', 'a', 'research', 'method', ',', 'a', 'discipline', ',', 'a', 'workflow', ',', 'and', 'a', 'profession', '.']\n",
      "['[', '4', ']', 'They', 'often', 'don’t', 'carry', 'consistent', 'signal', 'across', 'users', '.']\n",
      "['For', 'example', 'Data', 'science', 'is', '``', 'a', 'concept', 'to', 'unify', 'statistics', ',', 'data', 'analysis', ',', 'informatics', ',', 'and', 'their', 'related', 'methods', \"''\", 'to', '``', 'understand', 'and', 'analyze', 'actual', 'phenomena', \"''\", 'with', 'data', '.']\n",
      "['[', '5', ']', 'It', 'uses', 'techniques', 'and', 'theories', 'drawn', 'from', 'many', 'fields', 'within', 'the', 'context', 'of', 'mathematics', ',', 'statistics', ',', 'computer', 'science', ',', 'information', 'science', ',', 'and', 'domain', 'knowledge', '.']\n",
      "['[', '6', ']', 'However', ',', 'data', 'science', 'is', 'different', 'from', 'computer', 'science', 'and', 'information', 'science', '.']\n"
     ]
    }
   ],
   "source": [
    "for line in sentences:\n",
    "    print(tbwt.tokenize(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ed77a-09df-4955-bd96-8d1f31b99cc3",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "Refer to this website for porter stemmer documentation:  https://vijinimallawaarachchi.com/2017/05/09/porter-stemming-algorithm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae37bc06-5bd1-4417-bb1f-76886517c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['eating','eaten','eats','writing','writes','programming','programs','dancing','dancer','dances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff3be40a-0435-48ce-954f-808b078f0832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 porter stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6240253-f860-4cc2-9532-aba09992d7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stem of eating is ----> eat\n",
      "Stem of eaten is ----> eaten\n",
      "Stem of eats is ----> eat\n",
      "Stem of writing is ----> write\n",
      "Stem of writes is ----> write\n",
      "Stem of programming is ----> program\n",
      "Stem of programs is ----> program\n",
      "Stem of dancing is ----> danc\n",
      "Stem of dancer is ----> dancer\n",
      "Stem of dances is ----> danc\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"Stem of {word} is ----> {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8984a4c5-345d-443b-9b3f-6f958ae8c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratul\n",
      "celebr\n",
      "connect\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem('congratulations'))\n",
    "print(stemmer.stem('celebrations'))\n",
    "print(stemmer.stem('connection'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecd25617-7a3b-4a87-ba8f-6de679a8193c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIssues with stemming are that the stem obtained may not be a pre-existing word in the dictionary, as \\nobserved in the example above for the words dancing, dances, the stem obtained is not an \\npre-existing word, and the word may or may not be meaningful.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Issues with stemming are that the stem obtained may not be a pre-existing word in the dictionary, as \n",
    "observed in the example above for the words dancing, dances, the stem obtained is not an \n",
    "pre-existing word, and the word may or may not be meaningful.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c51beb-82d9-4a45-a2d6-3316fde24a61",
   "metadata": {},
   "source": [
    "### RegexpStemmer Class\n",
    "- NLTK has a RegexpStemmer class with the help of which we can easily implement regular expression stmmer algorithms.\n",
    "- It basically takes a single regular expression and removes any prefix or suffix that matches the expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "344a9923-f93a-47d6-9b36-7e8ae0433cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "rstemmer = RegexpStemmer('ing$|s$|e$|able$',min = 4)\n",
    "# this stemmer takes a regular expression base on which it decides what needs to be removed from the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ead83283-0f29-475e-bb6b-431ee2dc88dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eaten\n",
      "eat\n",
      "writ\n",
      "write\n",
      "programm\n",
      "program\n",
      "danc\n",
      "dancer\n",
      "dance\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(rstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9645a964-b9d0-40e5-93f8-a661e5be511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it is observed that it removed ing and s present in ords like eating,writes etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b654072-0a4a-4870-b36b-f1bd8a71fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowball Stemmer\n",
    "# It is beteer than the porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7414857a-bc50-4944-a643-c40abe475b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7297d07f-ce1f-48c5-ab69-5dce5a92f98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stem of eating is -----> eat\n",
      "Stem of eaten is -----> eaten\n",
      "Stem of eats is -----> eat\n",
      "Stem of writing is -----> write\n",
      "Stem of writes is -----> write\n",
      "Stem of programming is -----> program\n",
      "Stem of programs is -----> program\n",
      "Stem of dancing is -----> danc\n",
      "Stem of dancer is -----> dancer\n",
      "Stem of dances is -----> danc\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"Stem of {word} is -----> {snowstemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6dcaf1e-5352-4b84-b7cf-afead5376eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer\n",
      "Stem of fairly is ----> fairli\n",
      "Stem of sportingly is ----> sportingli\n",
      "Snowball Stemmer\n",
      "Stem of fairly is ----> fair\n",
      "Stem of sportingly is ----> sport\n"
     ]
    }
   ],
   "source": [
    "# Still, it fails for words like eaten, dancing, etc. \n",
    "# But it's better than Porter Stemmer, we can check it via example\n",
    "print('Porter Stemmer')\n",
    "print(f\"Stem of {'fairly'} is ----> {stemmer.stem('fairly')}\")\n",
    "print(f\"Stem of {'sportingly'} is ----> {stemmer.stem('sportingly')}\")\n",
    "print('Snowball Stemmer')\n",
    "print(f\"Stem of {'fairly'} is ----> {snowstemmer.stem('fairly')}\")\n",
    "print(f\"Stem of {'sportingly'} is ----> {snowstemmer.stem('sportingly')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71dfdeb9-54be-44c4-8869-ddc854c92956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As it can be observed that the ported stemmer fails for words fairly and sportingly \n",
    "# It produces irregular/meaningless words as stems such as fairli and spotingli \n",
    "# Whereas, Snowball Stemmer results in accurate stem for both the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bc38753-b5c6-4426-ba47-310c4a63bfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/harsh-\n",
      "[nltk_data]     ideapad/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bc2455a-479d-4a7d-8a72-5225e6924f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pos noun\n",
      "lemma/root word of eating is ----> eating\n",
      "lemma/root word of eaten is ----> eaten\n",
      "lemma/root word of eats is ----> eats\n",
      "lemma/root word of writing is ----> writing\n",
      "lemma/root word of writes is ----> writes\n",
      "lemma/root word of programming is ----> programming\n",
      "lemma/root word of programs is ----> program\n",
      "lemma/root word of dancing is ----> dancing\n",
      "lemma/root word of dancer is ----> dancer\n",
      "lemma/root word of dances is ----> dance\n",
      "for pos verb\n",
      "lemma/root word of eating is ----> eat\n",
      "lemma/root word of eaten is ----> eat\n",
      "lemma/root word of eats is ----> eat\n",
      "lemma/root word of writing is ----> write\n",
      "lemma/root word of writes is ----> write\n",
      "lemma/root word of programming is ----> program\n",
      "lemma/root word of programs is ----> program\n",
      "lemma/root word of dancing is ----> dance\n",
      "lemma/root word of dancer is ----> dancer\n",
      "lemma/root word of dances is ----> dance\n",
      "for pos adjective\n",
      "lemma/root word of eating is ----> eating\n",
      "lemma/root word of eaten is ----> eaten\n",
      "lemma/root word of eats is ----> eats\n",
      "lemma/root word of writing is ----> writing\n",
      "lemma/root word of writes is ----> writes\n",
      "lemma/root word of programming is ----> programming\n",
      "lemma/root word of programs is ----> programs\n",
      "lemma/root word of dancing is ----> dancing\n",
      "lemma/root word of dancer is ----> dancer\n",
      "lemma/root word of dances is ----> dances\n",
      "for pos adverb\n",
      "lemma/root word of eating is ----> eating\n",
      "lemma/root word of eaten is ----> eaten\n",
      "lemma/root word of eats is ----> eats\n",
      "lemma/root word of writing is ----> writing\n",
      "lemma/root word of writes is ----> writes\n",
      "lemma/root word of programming is ----> programming\n",
      "lemma/root word of programs is ----> programs\n",
      "lemma/root word of dancing is ----> dancing\n",
      "lemma/root word of dancer is ----> dancer\n",
      "lemma/root word of dances is ----> dances\n"
     ]
    }
   ],
   "source": [
    "pos_tag = {'noun':'n','verb':'v','adjective':'a','adverb':'r'}\n",
    "for p in pos_tag.keys():\n",
    "    print(f\"for pos {p}\")\n",
    "    for word in words:\n",
    "        print(f\"lemma/root word of {word} is ----> {lemmatizer.lemmatize(word,pos = pos_tag[p])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4672dde6-6edf-4b61-960a-998410318c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer takes 2 args: that is word and pos tag based on pos it reduces the word to lemms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45873c72-4f92-4412-8d26-e7812eaf12d7",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a55577f-9827-48a9-a307-ab34448af7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------- Before Porter Stemming --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/harsh-\n",
      "[nltk_data]     ideapad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Data science is an interdisciplinary academic field[1] that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge from potentially noisy, structured, or unstructured data.',\n",
       " '[2]\\nData science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).',\n",
       " '[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.',\n",
       " '[4]\\nThey often don’t carry consistent signal across users.',\n",
       " 'For example\\nData science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data.',\n",
       " '[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.',\n",
       " '[6] However, data science is different from computer science and information science.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------- After Porter Stemming ---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data scienc interdisciplinari academ field 1 use statist scientif comput scientif method process scientif visual algorithm system extract extrapol knowledg potenti noisi structur unstructur data',\n",
       " '2 data scienc also integr domain knowledg underli applic domain e.g. natur scienc inform technolog medicin',\n",
       " '3 data scienc multifacet describ scienc research paradigm research method disciplin workflow profess',\n",
       " '4 often ’ carri consist signal across user',\n",
       " \"exampl data scienc `` concept unifi statist data analysi informat relat method '' `` understand analyz actual phenomena '' data\",\n",
       " '5 use techniqu theori drawn mani field within context mathemat statist comput scienc inform scienc domain knowledg',\n",
       " '6 howev data scienc differ comput scienc inform scienc']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------- Using List Comprehension ------------------------------\n",
      "data scienc interdisciplinari academ field 1 use statist scientif comput scientif method process scientif visual algorithm system extract extrapol knowledg potenti noisi structur unstructur data\n",
      "2 data scienc also integr domain knowledg underli applic domain e.g. natur scienc inform technolog medicin\n",
      "3 data scienc multifacet describ scienc research paradigm research method disciplin workflow profess\n",
      "4 they often ’ carri consist signal across user\n",
      "for exampl data scienc `` concept unifi statist data analysi informat relat method '' `` understand analyz actual phenomena '' data\n",
      "5 it use techniqu theori drawn mani field within context mathemat statist comput scienc inform scienc domain knowledg\n",
      "6 howev data scienc differ comput scienc inform scienc\n"
     ]
    }
   ],
   "source": [
    "# Using porter Stemmer\n",
    "# Text Preprocessing with stopwords (words like the,on,their, etc which don't play any major role in nlp tasks \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "stopwords_eng = stopwords.words('english') # we can provide the language to get the stopwords for that language\n",
    "pstemmer = PorterStemmer()\n",
    "documents = nltk.sent_tokenize(corpus)  #top perform sentence wise tokenization\n",
    "print(\"----------------------------------------- Before Porter Stemming --------------------------------\")\n",
    "display(documents)\n",
    "non_stopwords_token = []\n",
    "lst = []\n",
    "i = 0\n",
    "for sentence in documents:\n",
    "    stemmed_sent = []\n",
    "    words = word_tokenize(sentence)\n",
    "    lst.append([pstemmer.stem(word) for word in words if word not in stopwords_eng and word not in r'[!@#$%^&*()_''\"\";,./;[]+}{:?><|~]'])\n",
    "    for word in word_tokenize(sentence):\n",
    "        if word.lower() not in stopwords_eng and word.lower() not in r'[!@#$%^&*()_''\"\";,./;[]+}{:?><|~]':\n",
    "            stemmed_sent.append(pstemmer.stem(word))\n",
    "    documents[i] = ' '.join(stemmed_sent)\n",
    "    i+=1\n",
    "print(\"----------------------------------------- After Porter Stemming ---------------------------------\")\n",
    "display(documents)\n",
    "print(\"----------------------------------------- Using List Comprehension ------------------------------\")\n",
    "for i in lst:\n",
    "    print(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f9febdc-b392-48c7-b4f5-c30fd5b4e64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------- Before Snowball Stemming --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/harsh-\n",
      "[nltk_data]     ideapad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Data science is an interdisciplinary academic field[1] that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge from potentially noisy, structured, or unstructured data.',\n",
       " '[2]\\nData science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).',\n",
       " '[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.',\n",
       " '[4]\\nThey often don’t carry consistent signal across users.',\n",
       " 'For example\\nData science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data.',\n",
       " '[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.',\n",
       " '[6] However, data science is different from computer science and information science.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------- After Snowball Stemming ---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data scienc interdisciplinari academ field 1 use statist scientif comput scientif method process scientif visual algorithm system extract extrapol knowledg potenti noisi structur unstructur data',\n",
       " '2 data scienc also integr domain knowledg under applic domain e.g. natur scienc inform technolog medicin',\n",
       " '3 data scienc multifacet describ scienc research paradigm research method disciplin workflow profess',\n",
       " '4 often ’ carri consist signal across user',\n",
       " \"exampl data scienc `` concept unifi statist data analysi informat relat method '' `` understand analyz actual phenomena '' data\",\n",
       " '5 use techniqu theori drawn mani field within context mathemat statist comput scienc inform scienc domain knowledg',\n",
       " '6 howev data scienc differ comput scienc inform scienc']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------- Using List Comprehension ------------------------------\n",
      "data scienc interdisciplinari academ field 1 use statist scientif comput scientif method process scientif visual algorithm system extract extrapol knowledg potenti noisi structur unstructur data\n",
      "2 data scienc also integr domain knowledg under applic domain e.g. natur scienc inform technolog medicin\n",
      "3 data scienc multifacet describ scienc research paradigm research method disciplin workflow profess\n",
      "4 they often ’ carri consist signal across user\n",
      "for exampl data scienc `` concept unifi statist data analysi informat relat method '' `` understand analyz actual phenomena '' data\n",
      "5 it use techniqu theori drawn mani field within context mathemat statist comput scienc inform scienc domain knowledg\n",
      "6 howev data scienc differ comput scienc inform scienc\n"
     ]
    }
   ],
   "source": [
    "# Using Snowball Stemmer\n",
    "# Text Preprocessing with stopwords (words like the,on,their, etc which don't play any major role in nlp tasks \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "stopwords_eng = stopwords.words('english') # we can provide the language to get the stopwords for that language\n",
    "sstemmer = SnowballStemmer('english')\n",
    "documents = nltk.sent_tokenize(corpus)  #top perform sentence wise tokenization\n",
    "print(\"----------------------------------------- Before Snowball Stemming --------------------------------\")\n",
    "display(documents)\n",
    "non_stopwords_token = []\n",
    "lst = []\n",
    "i = 0\n",
    "for sentence in documents:\n",
    "    stemmed_sent = []\n",
    "    words = word_tokenize(sentence)\n",
    "    lst.append([sstemmer.stem(word) for word in words if word not in stopwords_eng and word not in r'[!@#$%^&*()_''\"\";,./;[]+}{:?><|~]'])\n",
    "    for word in word_tokenize(sentence):\n",
    "        if word.lower() not in stopwords_eng and word.lower() not in r'[!@#$%^&*()_''\"\";,./;[]+}{:?><|~]':\n",
    "            stemmed_sent.append(sstemmer.stem(word))\n",
    "    documents[i] = ' '.join(stemmed_sent)\n",
    "    i+=1\n",
    "print(\"----------------------------------------- After Snowball Stemming ---------------------------------\")\n",
    "display(documents)\n",
    "print(\"----------------------------------------- Using List Comprehension ------------------------------\")\n",
    "for i in lst:\n",
    "    print(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79a32e77-28c0-4c56-8c72-99d3ed4f3987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------- Before Lemmatization --------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/harsh-\n",
      "[nltk_data]     ideapad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Data science is an interdisciplinary academic field[1] that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge from potentially noisy, structured, or unstructured data.',\n",
       " '[2]\\nData science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).',\n",
       " '[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.',\n",
       " '[4]\\nThey often don’t carry consistent signal across users.',\n",
       " 'For example\\nData science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data.',\n",
       " '[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.',\n",
       " '[6] However, data science is different from computer science and information science.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------- After Lemmatization ---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data science interdisciplinary academic field use statistics scientific compute scientific methods process scientific visualization algorithms systems extract extrapolate knowledge potentially noisy structure unstructured data',\n",
       " 'Data science also integrate domain knowledge underlie application domain e.g. natural sciences information technology medicine',\n",
       " 'Data science multifaceted describe science research paradigm research method discipline workflow profession',\n",
       " 'often ’ carry consistent signal across users',\n",
       " \"example Data science `` concept unify statistics data analysis informatics relate methods '' `` understand analyze actual phenomena '' data\",\n",
       " 'use techniques theories draw many field within context mathematics statistics computer science information science domain knowledge',\n",
       " 'However data science different computer science information science']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------- Using List Comprehension ------------------------------\n",
      "Data science interdisciplinary academic field us statistic scientific computing scientific method processing scientific visualization algorithm system extract extrapolate knowledge potentially noisy structured unstructured data\n",
      "Data science also integrates domain knowledge underlying application domain e.g. natural science information technology medicine\n",
      "Data science multifaceted described science research paradigm research method discipline workflow profession\n",
      "They often ’ carry consistent signal across user\n",
      "For example Data science `` concept unify statistic data analysis informatics related method '' `` understand analyze actual phenomenon '' data\n",
      "It us technique theory drawn many field within context mathematics statistic computer science information science domain knowledge\n",
      "However data science different computer science information science\n"
     ]
    }
   ],
   "source": [
    "# Using Snowball Stemmer\n",
    "# Text Preprocessing with stopwords (words like the,on,their, etc which don't play any major role in nlp tasks \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "stopwords_eng = stopwords.words('english') # we can provide the language to get the stopwords for that language\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "documents = nltk.sent_tokenize(corpus)  #top perform sentence wise tokenization\n",
    "print(\"----------------------------------------- Before Lemmatization --------------------------------\")\n",
    "display(documents)\n",
    "non_stopwords_token = []\n",
    "lst = []\n",
    "i = 0\n",
    "for sentence in documents:\n",
    "    stemmed_sent = []\n",
    "    words = word_tokenize(sentence)\n",
    "    lst.append([lemmatizer.lemmatize(word,'n') for word in words if word not in stopwords_eng and word not in r'[!@#$%^&*()_''\"\";,./;[]+}{:?><|~]' and not word.isnumeric()])\n",
    "    for word in word_tokenize(sentence):\n",
    "        if word.lower() not in stopwords_eng and word.lower() not in r'[!@#$%^&*()_''\"\";,./;[]+}{:?><|~]' and not word.isnumeric():\n",
    "            stemmed_sent.append(lemmatizer.lemmatize(word,'v'))\n",
    "    documents[i] = ' '.join(stemmed_sent)\n",
    "    i+=1\n",
    "print(\"----------------------------------------- After Lemmatization ---------------------------------\")\n",
    "display(documents)\n",
    "print(\"----------------------------------------- Using List Comprehension ------------------------------\")\n",
    "for i in lst:\n",
    "    print(\" \".join(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cbfe0e-9a98-439f-86c4-daa51bb990b5",
   "metadata": {},
   "source": [
    "# Pos Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a091ef-5670-4969-8385-a56555f87133",
   "metadata": {},
   "source": [
    "- CC coordinating conjunction \n",
    "- CD cardinal digit \n",
    "- DT determiner \n",
    "- EX existential there (like: \"there is\" ... think of it like \"there exists\") \n",
    "- FW foreign word \n",
    "- IN preposition/subordinating conjunction \n",
    "- JJ adjective - 'big'\n",
    "- JJR adjective, comparative - 'bigger'\n",
    "- JJS adjective, superlative - 'biggest'\n",
    "- LS list marker 1)\n",
    "- MD modal - could, will\n",
    "- NN noun, singular '- desk'\n",
    "- NNS noun plural - 'desks'\n",
    "- NNP proper noun, singular - 'Harrison'\n",
    "- NNPS proper noun, plural - 'Americans'\n",
    "- PDT predeterminer - 'all the kids'\n",
    "- POS possessive ending parent's\n",
    "- PRP personal pronoun -  I, he, she\n",
    "- PRP+(dollar-sign) possessive pronoun - my, his, hers \n",
    "- RB adverb - very, silently,\n",
    "- RBR adverb, comparative - better\n",
    "- RBS adverb, superlative - best\n",
    "- RP particle - give up\n",
    "- TO - to go 'to' the store.\n",
    "- UH interjection - errrrrrrrm\n",
    "- VB verb, base form - take\n",
    "- VBD verb, past tense - took\n",
    "- VBG verb, gerund/present participle - taking\n",
    "- VBN verb, past participle - taken\n",
    "- VBP verb, sing. present, non-3d - take\n",
    "- VBZ verb, 3rd person sing. present - takes\n",
    "- WDT wh-determiner - which\n",
    "- WP wh-pronoun - who, what\n",
    "- WP+(dollar-sign) possessive wh-pronoun, eg- whose\n",
    "- WRB wh-adverb, eg- where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6064c44e-6ec9-4100-b95d-815d1796ed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/harsh-\n",
      "[nltk_data]     ideapad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/harsh-ideapad/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_eng_lst = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8efa1d47-e196-4180-85d9-214624472d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_corpus = \"\"\"\n",
    "I have three visions for India. In 3000 years of our history people from all over the world have come and invaded us, captured our lands, conquered our minds. From Alexander onwards the Greeks, the Turks, the Moguls, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours. Yet we have not done this to any other nation. We have not conquered anyone. We have not grabbed their land, their culture and their history and tried to enforce our way of life on them. Why? Because we respect the freedom of others. That is why my FIRST VISION is that of FREEDOM. I believe that India got its first vision of this in 1857, when we started the war of Independence. It is this freedom that we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "\n",
    "We have 10 percent growth rate in most areas. Our poverty levels are falling. Our achievements are being globally recognised today. Yet we lack the self-confidence to see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect? MY SECOND VISION for India is DEVELOPMENT. For fifty years we have been a developing nation. It is time we see ourselves as a developed nation. We are among top five nations in the world in terms of GDP.\n",
    "\n",
    "I have a THIRD VISION. India must stand up to the world. Because I believe that unless India stands up to the world, no one will respect us. Only strength respects strength. We must be strong not only as a military power but also as an economic power. Both must go hand-in-hand. My good fortune was to have worked with three great minds. Dr.Vikram Sarabhai, of the Dept. of Space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material. I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.\n",
    "\n",
    "I was in Hyderabad giving this lecture, when a 14 year-old girl asked me for my autograph. I asked her what her goal in life is. She replied: I want to live in a developed India. For her, you and I will have to build this developed India. You must proclaim India is not an underdeveloped nation; it is a highly developed nation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ff1756a-778f-4a33-9b1f-1c445d107600",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_documents = sent_tokenize(pos_corpus.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb24b716-1470-4955-a644-ea72830d0f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('three', 'CD'), ('visions', 'NNS'), ('india', 'VBP')]\n",
      "[('years', 'NNS'), ('history', 'NN'), ('people', 'NNS'), ('world', 'NN'), ('come', 'VBP'), ('invaded', 'VBN'), ('us', 'PRP'), ('captured', 'JJ'), ('lands', 'NNS'), ('conquered', 'VBD'), ('minds', 'NNS')]\n",
      "[('alexander', 'NN'), ('onwards', 'NNS'), ('greeks', 'VBP'), ('turks', 'NNS'), ('moguls', 'VBP'), ('portuguese', 'JJ'), ('british', 'JJ'), ('french', 'JJ'), ('dutch', 'NN'), ('came', 'VBD'), ('looted', 'JJ'), ('us', 'PRP'), ('took', 'VBD')]\n",
      "[('yet', 'RB'), ('done', 'VBN'), ('nation', 'NN')]\n",
      "[('conquered', 'VBN'), ('anyone', 'NN')]\n",
      "[('grabbed', 'JJ'), ('land', 'NN'), ('culture', 'NN'), ('history', 'NN'), ('tried', 'VBD'), ('enforce', 'JJ'), ('way', 'NN'), ('life', 'NN')]\n",
      "[]\n",
      "[('respect', 'NN'), ('freedom', 'NN'), ('others', 'NNS')]\n",
      "[('first', 'JJ'), ('vision', 'NN'), ('freedom', 'NN')]\n",
      "[('believe', 'VB'), ('india', 'NN'), ('got', 'VBD'), ('first', 'JJ'), ('vision', 'NN'), ('started', 'VBD'), ('war', 'NN'), ('independence', 'NN')]\n",
      "[('freedom', 'NN'), ('must', 'MD'), ('protect', 'VB'), ('nurture', 'NN'), ('build', 'NN')]\n",
      "[('free', 'JJ'), ('one', 'CD'), ('respect', 'NN'), ('us', 'PRP')]\n",
      "[('percent', 'JJ'), ('growth', 'NN'), ('rate', 'NN'), ('areas', 'NNS')]\n",
      "[('poverty', 'NN'), ('levels', 'NNS'), ('falling', 'VBG')]\n",
      "[('achievements', 'NNS'), ('globally', 'RB'), ('recognised', 'VBD'), ('today', 'NN')]\n",
      "[('yet', 'RB'), ('lack', 'JJ'), ('self-confidence', 'NN'), ('see', 'NN'), ('developed', 'JJ'), ('nation', 'NN'), ('self-reliant', 'JJ'), ('self-assured', 'JJ')]\n",
      "[('’', 'NNS'), ('incorrect', 'VBP')]\n",
      "[('second', 'JJ'), ('vision', 'NN'), ('india', 'NN'), ('development', 'NN')]\n",
      "[('fifty', 'JJ'), ('years', 'NNS'), ('developing', 'VBG'), ('nation', 'NN')]\n",
      "[('time', 'NN'), ('see', 'VB'), ('developed', 'JJ'), ('nation', 'NN')]\n",
      "[('among', 'IN'), ('top', 'JJ'), ('five', 'CD'), ('nations', 'NNS'), ('world', 'NN'), ('terms', 'NNS'), ('gdp', 'VBP')]\n",
      "[('third', 'JJ'), ('vision', 'NN')]\n",
      "[('india', 'NN'), ('must', 'MD'), ('stand', 'VB'), ('world', 'NN')]\n",
      "[('believe', 'VB'), ('unless', 'IN'), ('india', 'JJ'), ('stands', 'VBZ'), ('world', 'NN'), ('one', 'CD'), ('respect', 'NN'), ('us', 'PRP')]\n",
      "[('strength', 'NN'), ('respects', 'NNS'), ('strength', 'NN')]\n",
      "[('must', 'MD'), ('strong', 'JJ'), ('military', 'JJ'), ('power', 'NN'), ('also', 'RB'), ('economic', 'JJ'), ('power', 'NN')]\n",
      "[('must', 'MD'), ('go', 'VB'), ('hand-in-hand', 'NN')]\n",
      "[('good', 'JJ'), ('fortune', 'NN'), ('worked', 'VBD'), ('three', 'CD'), ('great', 'JJ'), ('minds', 'NNS')]\n",
      "[('dr.vikram', 'NN'), ('sarabhai', 'NN'), ('dept', 'NN')]\n",
      "[('space', 'NN'), ('professor', 'NN'), ('satish', 'JJ'), ('dhawan', 'NN'), ('succeeded', 'VBD'), ('dr.', 'JJ'), ('brahm', 'NN'), ('prakash', 'NN'), ('father', 'NN'), ('nuclear', 'JJ'), ('material', 'NN')]\n",
      "[('lucky', 'JJ'), ('worked', 'VBD'), ('three', 'CD'), ('closely', 'RB'), ('consider', 'VBP'), ('great', 'JJ'), ('opportunity', 'NN'), ('life', 'NN')]\n",
      "[('hyderabad', 'NN'), ('giving', 'VBG'), ('lecture', 'JJ'), ('year-old', 'JJ'), ('girl', 'NN'), ('asked', 'VBD'), ('autograph', 'NNS')]\n",
      "[('asked', 'VBN'), ('goal', 'NN'), ('life', 'NN')]\n",
      "[('replied', 'VBN'), ('want', 'VBP'), ('live', 'JJ'), ('developed', 'VBN'), ('india', 'NN')]\n",
      "[('build', 'NN'), ('developed', 'VBD'), ('india', 'NN')]\n",
      "[('must', 'MD'), ('proclaim', 'VB'), ('india', 'NN'), ('underdeveloped', 'JJ'), ('nation', 'NN'), ('highly', 'RB'), ('developed', 'JJ'), ('nation', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for sentence in pos_documents:\n",
    "    words = word_tokenize(sentence)\n",
    "    lst = [word for word in words if word not in stopwords_eng_lst and not word.isnumeric() and word not in r'[~!@#$%^&*()`=+{}|:\"<>?[]\\;,./]']\n",
    "    print(nltk.pos_tag(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c57f626b-d620-4e65-9959-4db4d3e4a883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Taj', 'NNP'), ('Mahal', 'NNP'), ('beautiful', 'JJ'), ('Monument', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "final_lst = []\n",
    "for word in \"Taj Mahal is a beautiful Monument\".split():\n",
    "    if word not in stopwords_eng_lst:\n",
    "        final_lst.append(word)\n",
    "print(nltk.pos_tag(final_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacc231e-90b3-496b-9a9c-3ed3bceb98d1",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6d2c22f0-c7be-40d0-8635-936ee0e48195",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence =\"\"\"\n",
    "The Effiel tower was built from 1887 to 1889 by french engineer Gustave Effiel, \n",
    "whose company specialized in building metal frameworks and structures.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "923b048f-786a-4885-94d6-d34ad34230ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/harsh-\n",
      "[nltk_data]     ideapad/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to /home/harsh-\n",
      "[nltk_data]     ideapad/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "21395599-2065-4151-a7be-ed5ca34252a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1a18a6b4-91b3-4782-873f-f075bf954a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Effiel',\n",
       " 'tower',\n",
       " 'was',\n",
       " 'built',\n",
       " 'from',\n",
       " '1887',\n",
       " 'to',\n",
       " '1889',\n",
       " 'by',\n",
       " 'french',\n",
       " 'engineer',\n",
       " 'Gustave',\n",
       " 'Effiel',\n",
       " ',',\n",
       " 'whose',\n",
       " 'company',\n",
       " 'specialized',\n",
       " 'in',\n",
       " 'building',\n",
       " 'metal',\n",
       " 'frameworks',\n",
       " 'and',\n",
       " 'structures',\n",
       " '.']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "19512da6-7c8e-4523-a7fb-9f15b1793743",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tokens = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8e0739d0-a2eb-47bb-b149-9f98fd14cf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('Effiel', 'NNP'),\n",
       " ('tower', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('built', 'VBN'),\n",
       " ('from', 'IN'),\n",
       " ('1887', 'CD'),\n",
       " ('to', 'TO'),\n",
       " ('1889', 'CD'),\n",
       " ('by', 'IN'),\n",
       " ('french', 'JJ'),\n",
       " ('engineer', 'NN'),\n",
       " ('Gustave', 'NNP'),\n",
       " ('Effiel', 'NNP'),\n",
       " (',', ','),\n",
       " ('whose', 'WP$'),\n",
       " ('company', 'NN'),\n",
       " ('specialized', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('building', 'NN'),\n",
       " ('metal', 'NN'),\n",
       " ('frameworks', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('structures', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1990ccda-0c5a-4f40-b560-ba3389bf73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.ne_chunk(tagged_tokens).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734987c-a82d-4652-b9a0-cd56eb2b117c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spacy-env)",
   "language": "python",
   "name": "spacy-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
