{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a21253-ffbd-4960-8f00-fbee56dda9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question find the differences between nltk and spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73f6f985-4e31-49ae-b51f-39b4f100960f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/harsh-ideapad/anaconda3/lib/python3.12/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/harsh-ideapad/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/harsh-ideapad/anaconda3/lib/python3.12/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/harsh-ideapad/anaconda3/lib/python3.12/site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in /home/harsh-ideapad/anaconda3/lib/python3.12/site-packages (from nltk) (4.67.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/harsh-\n",
      "[nltk_data]     ideapad/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19cc013f-4d3e-4fb9-81fd-b384569e76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\" Data science is an interdisciplinary academic field[1] that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge from potentially noisy, structured, or unstructured data.[2]\n",
    "Data science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.[4]\n",
    "They often donâ€™t carry consistent signal across users. For example\n",
    "Data science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data.[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.[6] However, data science is different from computer science and information science.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7604e593-e013-4729-a50a-f29fb8c98445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data science is an interdisciplinary academic field[1] that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge from potentially noisy, structured, or unstructured data.[2]\n",
      "Data science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.[4]\n",
      "They often donâ€™t carry consistent signal across users. For example\n",
      "Data science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data.[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.[6] However, data science is different from computer science and information science.\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ae9ee32-6b39-40dc-b2a6-bc2cdae90a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "419f42f9-e391-48a4-a6e3-806548923d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "557de92e-3c27-4b81-af17-7e02cc04e41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Data science is an interdisciplinary academic field[1] that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge from potentially noisy, structured, or unstructured data.',\n",
       " '[2]\\nData science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).',\n",
       " '[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.',\n",
       " '[4]\\nThey often donâ€™t carry consistent signal across users.',\n",
       " 'For example\\nData science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data.',\n",
       " '[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.',\n",
       " '[6] However, data science is different from computer science and information science.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(sentences))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe7a5881-ff54-4d5d-9b28-bef8e2725595",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sentence-->words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d6b8d8c-22ef-414e-95f7-9f7f766029ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17ca0bc7-b90d-49a9-be1c-07168747825c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'an',\n",
       " 'interdisciplinary',\n",
       " 'academic',\n",
       " 'field',\n",
       " '[',\n",
       " '1',\n",
       " ']',\n",
       " 'that',\n",
       " 'uses',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'scientific',\n",
       " 'computing',\n",
       " ',',\n",
       " 'scientific',\n",
       " 'methods',\n",
       " ',',\n",
       " 'processing',\n",
       " ',',\n",
       " 'scientific',\n",
       " 'visualization',\n",
       " ',',\n",
       " 'algorithms',\n",
       " 'and',\n",
       " 'systems',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'or',\n",
       " 'extrapolate',\n",
       " 'knowledge',\n",
       " 'from',\n",
       " 'potentially',\n",
       " 'noisy',\n",
       " ',',\n",
       " 'structured',\n",
       " ',',\n",
       " 'or',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " '.',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'also',\n",
       " 'integrates',\n",
       " 'domain',\n",
       " 'knowledge',\n",
       " 'from',\n",
       " 'the',\n",
       " 'underlying',\n",
       " 'application',\n",
       " 'domain',\n",
       " '(',\n",
       " 'e.g.',\n",
       " ',',\n",
       " 'natural',\n",
       " 'sciences',\n",
       " ',',\n",
       " 'information',\n",
       " 'technology',\n",
       " ',',\n",
       " 'and',\n",
       " 'medicine',\n",
       " ')',\n",
       " '.',\n",
       " '[',\n",
       " '3',\n",
       " ']',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'multifaceted',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'described',\n",
       " 'as',\n",
       " 'a',\n",
       " 'science',\n",
       " ',',\n",
       " 'a',\n",
       " 'research',\n",
       " 'paradigm',\n",
       " ',',\n",
       " 'a',\n",
       " 'research',\n",
       " 'method',\n",
       " ',',\n",
       " 'a',\n",
       " 'discipline',\n",
       " ',',\n",
       " 'a',\n",
       " 'workflow',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'profession',\n",
       " '.',\n",
       " '[',\n",
       " '4',\n",
       " ']',\n",
       " 'They',\n",
       " 'often',\n",
       " 'don',\n",
       " 'â€™',\n",
       " 't',\n",
       " 'carry',\n",
       " 'consistent',\n",
       " 'signal',\n",
       " 'across',\n",
       " 'users',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'is',\n",
       " '``',\n",
       " 'a',\n",
       " 'concept',\n",
       " 'to',\n",
       " 'unify',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'data',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'informatics',\n",
       " ',',\n",
       " 'and',\n",
       " 'their',\n",
       " 'related',\n",
       " 'methods',\n",
       " \"''\",\n",
       " 'to',\n",
       " '``',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'actual',\n",
       " 'phenomena',\n",
       " \"''\",\n",
       " 'with',\n",
       " 'data',\n",
       " '.',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " 'It',\n",
       " 'uses',\n",
       " 'techniques',\n",
       " 'and',\n",
       " 'theories',\n",
       " 'drawn',\n",
       " 'from',\n",
       " 'many',\n",
       " 'fields',\n",
       " 'within',\n",
       " 'the',\n",
       " 'context',\n",
       " 'of',\n",
       " 'mathematics',\n",
       " ',',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'information',\n",
       " 'science',\n",
       " ',',\n",
       " 'and',\n",
       " 'domain',\n",
       " 'knowledge',\n",
       " '.',\n",
       " '[',\n",
       " '6',\n",
       " ']',\n",
       " 'However',\n",
       " ',',\n",
       " 'data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'different',\n",
       " 'from',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'and',\n",
       " 'information',\n",
       " 'science',\n",
       " '.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d498419-3bbe-4f75-9720-a16e60f7b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data', 'science', 'is', 'an', 'interdisciplinary', 'academic', 'field', '[', '1', ']', 'that', 'uses', 'statistics', ',', 'scientific', 'computing', ',', 'scientific', 'methods', ',', 'processing', ',', 'scientific', 'visualization', ',', 'algorithms', 'and', 'systems', 'to', 'extract', 'or', 'extrapolate', 'knowledge', 'from', 'potentially', 'noisy', ',', 'structured', ',', 'or', 'unstructured', 'data', '.']\n",
      "['[', '2', ']', 'Data', 'science', 'also', 'integrates', 'domain', 'knowledge', 'from', 'the', 'underlying', 'application', 'domain', '(', 'e.g.', ',', 'natural', 'sciences', ',', 'information', 'technology', ',', 'and', 'medicine', ')', '.']\n",
      "['[', '3', ']', 'Data', 'science', 'is', 'multifaceted', 'and', 'can', 'be', 'described', 'as', 'a', 'science', ',', 'a', 'research', 'paradigm', ',', 'a', 'research', 'method', ',', 'a', 'discipline', ',', 'a', 'workflow', ',', 'and', 'a', 'profession', '.']\n",
      "['[', '4', ']', 'They', 'often', 'don', 'â€™', 't', 'carry', 'consistent', 'signal', 'across', 'users', '.']\n",
      "['For', 'example', 'Data', 'science', 'is', '``', 'a', 'concept', 'to', 'unify', 'statistics', ',', 'data', 'analysis', ',', 'informatics', ',', 'and', 'their', 'related', 'methods', \"''\", 'to', '``', 'understand', 'and', 'analyze', 'actual', 'phenomena', \"''\", 'with', 'data', '.']\n",
      "['[', '5', ']', 'It', 'uses', 'techniques', 'and', 'theories', 'drawn', 'from', 'many', 'fields', 'within', 'the', 'context', 'of', 'mathematics', ',', 'statistics', ',', 'computer', 'science', ',', 'information', 'science', ',', 'and', 'domain', 'knowledge', '.']\n",
      "['[', '6', ']', 'However', ',', 'data', 'science', 'is', 'different', 'from', 'computer', 'science', 'and', 'information', 'science', '.']\n"
     ]
    }
   ],
   "source": [
    "for line in sentences:\n",
    "    print(word_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1274b4d-e995-4187-bce0-5bab285a86eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f2ed8ea-154f-4137-a2f7-38cbb44f0bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data', 'science', 'is', 'an', 'interdisciplinary', 'academic', 'field', '[', '1', ']', 'that', 'uses', 'statistics', ',', 'scientific', 'computing', ',', 'scientific', 'methods', ',', 'processing', ',', 'scientific', 'visualization', ',', 'algorithms', 'and', 'systems', 'to', 'extract', 'or', 'extrapolate', 'knowledge', 'from', 'potentially', 'noisy', ',', 'structured', ',', 'or', 'unstructured', 'data', '.']\n",
      "['[', '2', ']', 'Data', 'science', 'also', 'integrates', 'domain', 'knowledge', 'from', 'the', 'underlying', 'application', 'domain', '(', 'e', '.', 'g', '.,', 'natural', 'sciences', ',', 'information', 'technology', ',', 'and', 'medicine', ').']\n",
      "['[', '3', ']', 'Data', 'science', 'is', 'multifaceted', 'and', 'can', 'be', 'described', 'as', 'a', 'science', ',', 'a', 'research', 'paradigm', ',', 'a', 'research', 'method', ',', 'a', 'discipline', ',', 'a', 'workflow', ',', 'and', 'a', 'profession', '.']\n",
      "['[', '4', ']', 'They', 'often', 'don', 'â€™', 't', 'carry', 'consistent', 'signal', 'across', 'users', '.']\n",
      "['For', 'example', 'Data', 'science', 'is', '\"', 'a', 'concept', 'to', 'unify', 'statistics', ',', 'data', 'analysis', ',', 'informatics', ',', 'and', 'their', 'related', 'methods', '\"', 'to', '\"', 'understand', 'and', 'analyze', 'actual', 'phenomena', '\"', 'with', 'data', '.']\n",
      "['[', '5', ']', 'It', 'uses', 'techniques', 'and', 'theories', 'drawn', 'from', 'many', 'fields', 'within', 'the', 'context', 'of', 'mathematics', ',', 'statistics', ',', 'computer', 'science', ',', 'information', 'science', ',', 'and', 'domain', 'knowledge', '.']\n",
      "['[', '6', ']', 'However', ',', 'data', 'science', 'is', 'different', 'from', 'computer', 'science', 'and', 'information', 'science', '.']\n"
     ]
    }
   ],
   "source": [
    "for line in sentences:\n",
    "    print(wordpunct_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a43c99cf-bf09-4b3e-9be3-25d71eaf2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tbwt = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "393d923c-d662-49ac-a7c7-621e95d90294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data', 'science', 'is', 'an', 'interdisciplinary', 'academic', 'field', '[', '1', ']', 'that', 'uses', 'statistics', ',', 'scientific', 'computing', ',', 'scientific', 'methods', ',', 'processing', ',', 'scientific', 'visualization', ',', 'algorithms', 'and', 'systems', 'to', 'extract', 'or', 'extrapolate', 'knowledge', 'from', 'potentially', 'noisy', ',', 'structured', ',', 'or', 'unstructured', 'data', '.']\n",
      "['[', '2', ']', 'Data', 'science', 'also', 'integrates', 'domain', 'knowledge', 'from', 'the', 'underlying', 'application', 'domain', '(', 'e.g.', ',', 'natural', 'sciences', ',', 'information', 'technology', ',', 'and', 'medicine', ')', '.']\n",
      "['[', '3', ']', 'Data', 'science', 'is', 'multifaceted', 'and', 'can', 'be', 'described', 'as', 'a', 'science', ',', 'a', 'research', 'paradigm', ',', 'a', 'research', 'method', ',', 'a', 'discipline', ',', 'a', 'workflow', ',', 'and', 'a', 'profession', '.']\n",
      "['[', '4', ']', 'They', 'often', 'donâ€™t', 'carry', 'consistent', 'signal', 'across', 'users', '.']\n",
      "['For', 'example', 'Data', 'science', 'is', '``', 'a', 'concept', 'to', 'unify', 'statistics', ',', 'data', 'analysis', ',', 'informatics', ',', 'and', 'their', 'related', 'methods', \"''\", 'to', '``', 'understand', 'and', 'analyze', 'actual', 'phenomena', \"''\", 'with', 'data', '.']\n",
      "['[', '5', ']', 'It', 'uses', 'techniques', 'and', 'theories', 'drawn', 'from', 'many', 'fields', 'within', 'the', 'context', 'of', 'mathematics', ',', 'statistics', ',', 'computer', 'science', ',', 'information', 'science', ',', 'and', 'domain', 'knowledge', '.']\n",
      "['[', '6', ']', 'However', ',', 'data', 'science', 'is', 'different', 'from', 'computer', 'science', 'and', 'information', 'science', '.']\n"
     ]
    }
   ],
   "source": [
    "for line in sentences:\n",
    "    print(tbwt.tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4884a343-2f70-4920-b57b-d617fe300745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae37bc06-5bd1-4417-bb1f-76886517c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['eating','eaten','eats','writing','writes','programming','programs','dancing','dancer','dances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff3be40a-0435-48ce-954f-808b078f0832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 porter stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6240253-f860-4cc2-9532-aba09992d7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stem of eating is ----> eat\n",
      "Stem of eaten is ----> eaten\n",
      "Stem of eats is ----> eat\n",
      "Stem of writing is ----> write\n",
      "Stem of writes is ----> write\n",
      "Stem of programming is ----> program\n",
      "Stem of programs is ----> program\n",
      "Stem of dancing is ----> danc\n",
      "Stem of dancer is ----> dancer\n",
      "Stem of dances is ----> danc\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"Stem of {word} is ----> {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8984a4c5-345d-443b-9b3f-6f958ae8c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratul\n",
      "celebr\n",
      "connect\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem('congratulations'))\n",
    "print(stemmer.stem('celebrations'))\n",
    "print(stemmer.stem('connection'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ecd25617-7a3b-4a87-ba8f-6de679a8193c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIssue with stemming is the stem obtained may not be a pre existing word in dictionary as \\nobserved in example above for the words dancing dances the stem obtained is not any \\npre-existing word.\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Issues with stemming are that the stem obtained may not be a pre-existing word in the dictionary, as \n",
    "observed in the example above for the words dancing, dances, the stem obtained is not an \n",
    "pre-existing word, and the word may or may not be meaningful.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ce38150-8fcd-46d3-a6a5-c97c3c14d171",
   "metadata": {},
   "source": [
    "In linguistics (study of language and its structure), a stem is part of a word, that is common to all of its inflected variants.\n",
    "\n",
    "    CONNECT\n",
    "    CONNECTED\n",
    "    CONNECTION\n",
    "    CONNECTING\n",
    "\n",
    "Above words are inflected variants of CONNECT. Hence, CONNECT is a stem. To this stem we can add different suffixes to form different words.\n",
    "\n",
    "The process of reducing such inflected (or sometimes derived) words to their word stem is known as Stemming. For example, CONNECTED, CONNECTION and CONNECTING can be reduced to the stem CONNECT.\n",
    "\n",
    "The Porter Stemming algorithm (or Porter Stemmer) is used to remove the suffixes from an English word and obtain its stem which becomes very useful in the field of Information Retrieval (IR). This process reduces the number of terms kept by an IR system which will be advantageous both in terms of space and time complexity. This algorithm was developed by a British Computer Scientist named  Martin F. Porter. You can visit the official home page of the Porter stemming algorithm for further information.\n",
    "\n",
    "First, a few terms and expressions will be introduced, which will be helpful for the ease of explanation.\n",
    "Consonants and Vowels\n",
    "\n",
    "A consonant is a letter other than the vowels and other than a letter â€œYâ€ preceded by a consonant. So in â€œTOYâ€ the consonants are â€œTâ€ and â€œYâ€, and in â€œSYZYGYâ€ they are â€œSâ€, â€œZâ€ and â€œGâ€.\n",
    "\n",
    "If a letter is not a consonant it is a vowel.\n",
    "\n",
    "A consonant will be denoted by c and a vowel by v.\n",
    "\n",
    "A list of one or more consecutive consonants (cccâ€¦) will be denoted by C, and a list of one or more consecutive vowels (vvvâ€¦) will be denoted by V. Any word, or part of a word, therefore has one of the four forms given below.\n",
    "\n",
    "    CVCV â€¦ C â†’ collection, management\n",
    "    CVCV â€¦ V â†’ conclude, revise\n",
    "    VCVC â€¦ C â†’ entertainment, illumination\n",
    "    VCVC â€¦ V â†’ illustrate, abundance\n",
    "\n",
    "All of these forms can be represented using a single form as,\n",
    "\n",
    "    [C]VCVC â€¦ [V]\n",
    "\n",
    "Here the square brackets denote arbitrary presence of consonants or vowels.\n",
    "\n",
    "(VC)m denotes VC repeated m times. So the above expression can be written as,\n",
    "\n",
    "    [C](VC)m[V]\n",
    "\n",
    "What is m?\n",
    "\n",
    "The value m found in the above expression is called the measure of any word or word part when represented in the form [C](VC)m[V]. Here are some examples for different values of m:\n",
    "\n",
    "    m=0   â†’   TREE, TR, EE, Y, BY\n",
    "    m=1   â†’   TROUBLE, OATS, TREES, IVY\n",
    "    m=2   â†’   TROUBLES, PRIVATE, OATEN, ROBBERY\n",
    "\n",
    "Stemmer\n",
    "Rules\n",
    "\n",
    "The rules for replacing (or removing) a suffix will be given in the form as shown below.\n",
    "\n",
    "    (condition) S1 â†’ S2\n",
    "\n",
    "This means that if a word ends with the suffix S1, and the stem before S1 satisfies the given condition, S1 is replaced by S2. The condition is usually given in terms of m in regard to the stem before S1.\n",
    "\n",
    "    (m > 1) EMENT â†’\n",
    "\n",
    "Here S1 is â€˜EMENTâ€™ and S2 is null. This would map REPLACEMENT to REPLAC, since REPLAC is a word part for which m = 2.\n",
    "Conditions\n",
    "\n",
    "The conditions may contain the following:\n",
    "\n",
    "    *S    â€“    the stem ends with S (and similarly for the other letters)\n",
    "    *v*  â€“    the stem contains a vowel\n",
    "    *d    â€“    the stem ends with a double consonant (e.g. -TT, -SS)\n",
    "    *o    â€“    the stem ends cvc, where the second c is not W, X or Y (e.g. -WIL, -HOP)\n",
    "\n",
    "And the condition part may also contain expressions with and, or and not.\n",
    "\n",
    "    (m>1 and (*S or *T)) tests for a stem with m>1 ending in S or T.\n",
    "\n",
    "    (*d and not (*L or *S or *Z)) tests for a stem ending with a double consonant and does not end with letters L, S or Z.\n",
    "\n",
    "How rules are obeyed?\n",
    "\n",
    "In a set of rules written beneath each other, only one is obeyed, and this will be the one with the longest matching S1 for the given word. For example, with the following rules,\n",
    "\n",
    "        SSES       â†’           SS\n",
    "        IES          â†’           I\n",
    "        SS            â†’          SS\n",
    "        S              â†’\n",
    "\n",
    "(Here the conditions are all null) CARESSES maps to CARESS since SSES is the longest match for S1. Equally CARESS maps to CARESS (since S1=â€SSâ€) and CARES to CARE (since S1=â€Sâ€).\n",
    "The Algorithm\n",
    "Step 1a\n",
    "\n",
    "        SSES       â†’           SS\n",
    "        IES          â†’           I\n",
    "        SS           â†’           SS\n",
    "        S             â†’\n",
    "\n",
    "Step 1b\n",
    "\n",
    "        (m>0) EED           â†’           EE\n",
    "        (*v*) ED               â†’\n",
    "        (*v*) ING             â†’\n",
    "\n",
    "If the second or third of the rules in Step 1b is successful, the following is performed.\n",
    "\n",
    "        AT            â†’             ATE\n",
    "        BL            â†’             BLE\n",
    "        IZ             â†’             IZE\n",
    "        (*d and not (*L or *S or *Z))             â†’             single letter\n",
    "        (m=1 and *o)             â†’             E\n",
    "\n",
    "Step 1c\n",
    "\n",
    "        (*v*) Y             â†’             I\n",
    "\n",
    "Step 2\n",
    "\n",
    "        (m>0) ATIONAL                â†’                           ATE\n",
    "        (m>0) TIONAL                   â†’                           TION\n",
    "        (m>0) ENCI                         â†’                           ENCE\n",
    "        (m>0) ANCI                         â†’                           ANCE\n",
    "        (m>0) IZER                          â†’                           IZE\n",
    "        (m>0) ABLI                          â†’                           ABLE\n",
    "        (m>0) ALLI                          â†’                           AL\n",
    "        (m>0) ENTLI                        â†’                           ENT\n",
    "        (m>0) ELI                             â†’                           E\n",
    "        (m>0) OUSLI                        â†’                           OUS\n",
    "        (m>0) IZATION                    â†’                           IZE\n",
    "        (m>0) ATION                       â†’                           ATE\n",
    "        (m>0) ATOR                         â†’                           ATE\n",
    "        (m>0) ALISM                       â†’                           AL\n",
    "        (m>0) IVENESS                   â†’                           IVE\n",
    "        (m>0) FULNESS                  â†’                           FUL\n",
    "        (m>0) OUSNESS                  â†’                           OUS\n",
    "        (m>0) ALITI                         â†’                           AL\n",
    "        (m>0) IVITI                          â†’                           IVE\n",
    "        (m>0) BILITI                        â†’                           BLE\n",
    "\n",
    "Step 3\n",
    "\n",
    "        (m>0) ICATE                       â†’                           IC\n",
    "        (m>0) ATIVE                       â†’\n",
    "        (m>0) ALIZE                        â†’                           AL\n",
    "        (m>0) ICITI                          â†’                           IC\n",
    "        (m>0) ICAL                          â†’                           IC\n",
    "        (m>0) FUL                           â†’\n",
    "        (m>0) NESS                         â†’\n",
    "\n",
    "Step 4\n",
    "\n",
    "        (m>1) AL                             â†’\n",
    "        (m>1) ANCE                        â†’\n",
    "        (m>1) ENCE                        â†’\n",
    "        (m>1) ER                              â†’\n",
    "        (m>1) IC                               â†’\n",
    "        (m>1) ABLE                         â†’\n",
    "        (m>1) IBLE                          â†’\n",
    "        (m>1) ANT                           â†’\n",
    "        (m>1) EMENT                     â†’\n",
    "        (m>1) MENT                        â†’\n",
    "        (m>1) ENT                           â†’\n",
    "        (m>1 and (*S or *T)) ION             â†’\n",
    "        (m>1) OU                            â†’\n",
    "        (m>1) ISM                           â†’\n",
    "        (m>1) ATE                           â†’\n",
    "        (m>1) ITI                              â†’\n",
    "        (m>1) OUS                           â†’\n",
    "        (m>1) IVE                            â†’\n",
    "        (m>1) IZE                            â†’\n",
    "\n",
    "Step 5a\n",
    "\n",
    "        (m>1) E                                â†’\n",
    "        (m=1 and not *o) E            â†’\n",
    "\n",
    "Step 5b\n",
    "\n",
    "        (m > 1 and *d and *L)        â†’               single letter\n",
    "\n",
    "For each word you input to the algorithm, all the steps from 1 to 5 will be executed and the output will be produced at the end.\n",
    "Example Inputs\n",
    "\n",
    "Letâ€™s consider a few example inputs and check what will be their stem outputs. ðŸ™‚\n",
    "Example 1\n",
    "\n",
    "In the first example, we input the word MULTIDIMENSIONAL to the Porter Stemming algorithm. Letâ€™s see what happens as the word goes through steps 1 to 5.\n",
    "\n",
    "ex.png\n",
    "\n",
    "    The suffix will not match any of the cases found in steps 1, 2 and 3.\n",
    "    Then it comes to step 4.\n",
    "    The stem of the word has m > 1 (since m = 5) and ends with â€œALâ€.\n",
    "    Hence in step 4, â€œALâ€ is deleted (replaced with null).\n",
    "    Calling step 5 will not change the stem further.\n",
    "    Finally the output will be MULTIDIMENSION.\n",
    "\n",
    "    MULTIDIMENSIONAL â†’ MULTIDIMENSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c51beb-82d9-4a45-a2d6-3316fde24a61",
   "metadata": {},
   "source": [
    "### RegexpStemmer Class\n",
    "- NLTK has a RegexpStemmer class with the help of which we can easily implement regular expression stmmer algorithms.\n",
    "- It basically takes a single regular expression and removes any prefix or suffix that matches the expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "344a9923-f93a-47d6-9b36-7e8ae0433cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "rstemmer = RegexpStemmer('ing$|s$|e$|able$',min = 4)\n",
    "# this stemmer takes a regular expression base on which it decides what needs to be removed from the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ead83283-0f29-475e-bb6b-431ee2dc88dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eaten\n",
      "eat\n",
      "writ\n",
      "write\n",
      "programm\n",
      "program\n",
      "danc\n",
      "dancer\n",
      "dance\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(rstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9645a964-b9d0-40e5-93f8-a661e5be511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it is observed that it removed ing and s present in ords like eating,writes etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b654072-0a4a-4870-b36b-f1bd8a71fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowball Stemmer\n",
    "# It is beteer than the porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7414857a-bc50-4944-a643-c40abe475b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7297d07f-ce1f-48c5-ab69-5dce5a92f98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stem of eating is -----> eat\n",
      "Stem of eaten is -----> eaten\n",
      "Stem of eats is -----> eat\n",
      "Stem of writing is -----> write\n",
      "Stem of writes is -----> write\n",
      "Stem of programming is -----> program\n",
      "Stem of programs is -----> program\n",
      "Stem of dancing is -----> danc\n",
      "Stem of dancer is -----> dancer\n",
      "Stem of dances is -----> danc\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"Stem of {word} is -----> {snowstemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d6dcaf1e-5352-4b84-b7cf-afead5376eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer\n",
      "Stem of fairly is ----> fairli\n",
      "Stem of sportingly is ----> sportingli\n",
      "Snowball Stemmer\n",
      "Stem of fairly is ----> fair\n",
      "Stem of sportingly is ----> sport\n"
     ]
    }
   ],
   "source": [
    "# Still, it fails for words like eaten, dancing, etc. \n",
    "# But it's better than Porter Stemmer, we can check it via example\n",
    "print('Porter Stemmer')\n",
    "print(f\"Stem of {'fairly'} is ----> {stemmer.stem('fairly')}\")\n",
    "print(f\"Stem of {'sportingly'} is ----> {stemmer.stem('sportingly')}\")\n",
    "print('Snowball Stemmer')\n",
    "print(f\"Stem of {'fairly'} is ----> {snowstemmer.stem('fairly')}\")\n",
    "print(f\"Stem of {'sportingly'} is ----> {snowstemmer.stem('sportingly')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "71dfdeb9-54be-44c4-8869-ddc854c92956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As it can be observed that the ported stemmer fails for words fairly and sportingly \n",
    "# It produces irregular/meaningless words as stems such as fairli and spotingli \n",
    "# Whereas, Snowball Stemmer results in accurate stem for both the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5bc38753-b5c6-4426-ba47-310c4a63bfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/harsh-\n",
      "[nltk_data]     ideapad/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1bc2455a-479d-4a7d-8a72-5225e6924f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pos noun\n",
      "lemma/root word of eating is ----> eating\n",
      "lemma/root word of eaten is ----> eaten\n",
      "lemma/root word of eats is ----> eats\n",
      "lemma/root word of writing is ----> writing\n",
      "lemma/root word of writes is ----> writes\n",
      "lemma/root word of programming is ----> programming\n",
      "lemma/root word of programs is ----> program\n",
      "lemma/root word of dancing is ----> dancing\n",
      "lemma/root word of dancer is ----> dancer\n",
      "lemma/root word of dances is ----> dance\n",
      "for pos verb\n",
      "lemma/root word of eating is ----> eat\n",
      "lemma/root word of eaten is ----> eat\n",
      "lemma/root word of eats is ----> eat\n",
      "lemma/root word of writing is ----> write\n",
      "lemma/root word of writes is ----> write\n",
      "lemma/root word of programming is ----> program\n",
      "lemma/root word of programs is ----> program\n",
      "lemma/root word of dancing is ----> dance\n",
      "lemma/root word of dancer is ----> dancer\n",
      "lemma/root word of dances is ----> dance\n",
      "for pos adjective\n",
      "lemma/root word of eating is ----> eating\n",
      "lemma/root word of eaten is ----> eaten\n",
      "lemma/root word of eats is ----> eats\n",
      "lemma/root word of writing is ----> writing\n",
      "lemma/root word of writes is ----> writes\n",
      "lemma/root word of programming is ----> programming\n",
      "lemma/root word of programs is ----> programs\n",
      "lemma/root word of dancing is ----> dancing\n",
      "lemma/root word of dancer is ----> dancer\n",
      "lemma/root word of dances is ----> dances\n",
      "for pos adverb\n",
      "lemma/root word of eating is ----> eating\n",
      "lemma/root word of eaten is ----> eaten\n",
      "lemma/root word of eats is ----> eats\n",
      "lemma/root word of writing is ----> writing\n",
      "lemma/root word of writes is ----> writes\n",
      "lemma/root word of programming is ----> programming\n",
      "lemma/root word of programs is ----> programs\n",
      "lemma/root word of dancing is ----> dancing\n",
      "lemma/root word of dancer is ----> dancer\n",
      "lemma/root word of dances is ----> dances\n"
     ]
    }
   ],
   "source": [
    "pos_tag = {'noun':'n','verb':'v','adjective':'a','adverb':'r'}\n",
    "for p in pos_tag.keys():\n",
    "    print(f\"for pos {p}\")\n",
    "    for word in words:\n",
    "        print(f\"lemma/root word of {word} is ----> {lemmatizer.lemmatize(word,pos = pos_tag[p])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4672dde6-6edf-4b61-960a-998410318c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer takes 2 args: that is word and pos tag based on pos it reduces the word to lemms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473e605-4cfb-4720-b4bf-4db7b23b93a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spacy-env)",
   "language": "python",
   "name": "spacy-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
